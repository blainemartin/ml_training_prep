{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blainemartin/ml_training_prep/blob/main/Star_Trek_ML_Training_Data_Prep_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Training Data Prep Tool (Star Trek)\n",
        "\n",
        "This is an all-in-one tool for creating consolidated training data sets to support the creation of \"Game Master\" chatbots for Star Trek text-based adventures. This can be run in a non-GPU instance. This tool has the capability of compiling the following training data for use LLM Lora training:\n",
        "\n",
        "*   Episode/Movie Scripts\n",
        "*   YouTube Playlist Subtitle Transcriptions\n",
        "*   Wiki Articles (Memory-Alpha, Memory-Beta, and Wikipedia supported)\n",
        "\n",
        "Steps 1.x ensure you have a consistent connection, and the right runtime type provisioned.\n",
        "\n",
        "Steps 2.x prepare the folder structure that will be used in later training stages. These steps also download data into the /training/dataset folder.\n",
        "\n",
        "Step 3 consolidates all of the data obtained in step 2 into one subfolder at /content/text-generation-webui/training/dataset/consolidated which can be used by the raw data input portion of the Web UI training module.\n",
        "[link text](https://)"
      ],
      "metadata": {
        "id": "MFQl6-FjSYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.0 Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "#@title 1.1 GPU Check { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.2 Memory Check { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "zSg7o4V5DBL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2.0 Prep File Structure & Training Data\n",
        "%cd /content\n",
        "!git clone https://github.com/oobabooga/text-generation-webui\n",
        "#!git clone https://github.com/camenduru/text-generation-webui"
      ],
      "metadata": {
        "id": "QiAYG3yGQaFx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2.1 Star Trek Episode Scripts\n",
        "series = \"TNG,TOS,DS9,VOY\" # @param {type:\"string\"}\n",
        "\n",
        "#Return to home\n",
        "%cd /content\n",
        "#Use the git clone command to clone the repository:\n",
        "!git clone https://github.com/blainemartin/ml_training_prep.git\n",
        "#Navigate into the new directory:\n",
        "%cd ml_training_prep\n",
        "#Then, navigate into the ST:TNG Episode Scripts directory:\n",
        "%cd \"Star Trek Episode Scripts\"\n",
        "#Install required Python modules\n",
        "!pip install -r requirements.txt\n",
        "#Now run the script. Use argument to specify output directory.\n",
        "!python script_downloader.py {series} /content/text-generation-webui/training/datasets/Scripts\n"
      ],
      "metadata": {
        "id": "4NxqVxlIB_Jg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2.2 YouTube Commentary\n",
        "output_dir = \"/content/text-generation-webui/training/datasets/Commentary\" # @param {type:\"string\"}\n",
        "\n",
        "#Return to home\n",
        "%cd /content\n",
        "#Use the git clone/pull command to clone/update the repository:\n",
        "!git clone https://github.com/blainemartin/ml_training_prep.git || (!cd ml_training_prep && git pull)\n",
        "%cd /content\n",
        "#Navigate into the new directory:\n",
        "%cd ml_training_prep\n",
        "#Then, navigate into the YouTube Scripts directory:\n",
        "%cd \"YouTube Transcripts\"\n",
        "#Install required Python modules\n",
        "!pip install yt-dlp\n",
        "#Now run the script. Use argument to specify playlist URL and output directory.\n",
        "playlist_urls = [\n",
        "    \"https://www.youtube.com/playlist?list=PLLs9RolP5tC5BnuJq4z5P6UOzyjRfkBQV\",\n",
        "    \"https://www.youtube.com/playlist?list=PL0bMaYlUR-3D22hUlvSuhpOAzLei2jkA_\",\n",
        "     \"https://www.youtube.com/playlist?list=PL5Pso33oqJDidBC83byR7Mlna6gak_4fx\",\n",
        "     \"https://www.youtube.com/playlist?list=PLAXhpI9PdbZYF9gX4d8SHTk56eQ7w912Q\",\n",
        "     \"https://www.youtube.com/playlist?list=PL8FWJwq6-Yp50V5fM_uGfh1BwFNDeKRJW\"\n",
        "     \"https://www.youtube.com/playlist?list=PLjNbxX7w4eojMaTakwmoqbDF9BXG1j6FI\"\n",
        "]\n",
        "\n",
        "for url in playlist_urls:\n",
        "    !python transcripts_downloader.py {url} {output_dir}\n"
      ],
      "metadata": {
        "id": "UxdpHEiDpeVM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2.3 Wiki Articles\n",
        "series = \"TNG,DS9,YOY,TOS\" # @param {type:\"string\"}\n",
        "wikis = \"MemAlpha,Wikipedia\" # @param {type:\"string\"}\n",
        "output_dir = \"/content/text-generation-webui/training/datasets/Wiki\" # @param {type:\"string\"}\n",
        "\n",
        "#Return to home\n",
        "%cd /content\n",
        "#Use the git clone/pull command to clone/update the repository:\n",
        "!git clone https://github.com/blainemartin/ml_training_prep.git || (!cd ml_training_prep && git pull)\n",
        "%cd /content\n",
        "#Navigate into the new directory:\n",
        "%cd ml_training_prep\n",
        "#Then, navigate into the YouTube Scripts directory:\n",
        "%cd \"Star Trek Wiki Articles\"\n",
        "#Install required Python modules\n",
        "!pip install requests beautifulsoup4 urljoin\n",
        "#Now run the script. Use argument to specify playlist URL and output directory.\n",
        "!python article_downloader.py {series} {wikis} {output_dir}\n"
      ],
      "metadata": {
        "id": "Mnz96ss7i3Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.0 Consolidate .txt files for Text Generation Web UI training module(s)\n",
        "#%cd /content\n",
        "#%cd ml_training_prep\n",
        "#!python txt_consolidator.py /content/text-generation-webui/training/datasets\n",
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "# Define paths\n",
        "base_path = \"/content/text-generation-webui/training/datasets\"\n",
        "consolidated_folder_path = os.path.join(base_path, \"consolidated\")\n",
        "consolidated_file_path = os.path.join(base_path, \"consolidated.txt\")\n",
        "trainer_datasets_file_path = os.path.join(base_path, \"put-trainer-datasets-here.txt\")\n",
        "new_consolidated_folder_path = \"/content/consolidated\"\n",
        "\n",
        "# Delete existing folder and files if they exist\n",
        "for path in [consolidated_folder_path, consolidated_file_path, trainer_datasets_file_path]:\n",
        "    if os.path.exists(path):\n",
        "        if os.path.isfile(path):\n",
        "            os.remove(path)\n",
        "        else:\n",
        "            shutil.rmtree(path)\n",
        "\n",
        "# Create new consolidated folder if it doesn't exist\n",
        "os.makedirs(new_consolidated_folder_path, exist_ok=True)\n",
        "\n",
        "# Copy all .txt files to the new consolidated folder\n",
        "for dirpath, dirnames, filenames in os.walk(base_path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('.txt'):\n",
        "            # Create a new filename based on the original file's directory\n",
        "            new_filename = filename\n",
        "            counter = 1\n",
        "            while os.path.exists(os.path.join(new_consolidated_folder_path, new_filename)):\n",
        "                name, ext = os.path.splitext(filename)\n",
        "                new_filename = f\"{name}_{counter}{ext}\"\n",
        "                counter += 1\n",
        "            shutil.copy(os.path.join(dirpath, filename), os.path.join(new_consolidated_folder_path, new_filename))\n",
        "\n",
        "# Copy the new consolidated folder to the original location\n",
        "shutil.copytree(new_consolidated_folder_path, consolidated_folder_path)\n",
        "\n",
        "# Concatenate all .txt files in the consolidated folder\n",
        "with open(consolidated_file_path, 'w') as outfile:\n",
        "    for filename in glob.glob(os.path.join(consolidated_folder_path, '*.txt')):\n",
        "        with open(filename, 'r') as readfile:\n",
        "            outfile.write(readfile.read() + '\\n' * 3)\n",
        "\n"
      ],
      "metadata": {
        "id": "O6wGL8hdTjZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.1 Export Dataset to Google Drive\n",
        "\n",
        "%cd /content/text-generation-webui/training/datasets\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "#Mount Google Drive to /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the file and directory paths\n",
        "file_path = \"/content/drive/MyDrive/ST_ML_Training_Set.zip\"\n",
        "dir_path = \"/content/text-generation-webui/training/datasets\"\n",
        "\n",
        "# Delete the file if it exists\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "\n",
        "# Create a zip file from the directory\n",
        "shutil.make_archive(\"/content/drive/MyDrive/ST_ML_Training_Set\", 'zip', dir_path, \"consolidated\")"
      ],
      "metadata": {
        "id": "db7Xug6hNZHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}